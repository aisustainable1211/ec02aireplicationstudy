{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Welcome to the Eco2AI Replication Project**\n"
      ],
      "metadata": {
        "id": "dK8L7-ddSt1i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook replicates selected results from the paper **\"Eco2AI: A Framework for Energy Consumption and COâ‚‚ Emission Tracking in AI Experiments\"** (Budennyy et al., 2022)."
      ],
      "metadata": {
        "id": "YE_wtJXvS68Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The aim of this project was to reproduce key emission tracking outputs by training a simple Convolutional Neural Network (CNN) on the MNIST dataset while logging carbon emissions using the Eco2AI Python package."
      ],
      "metadata": {
        "id": "3P_pdFQjS3dm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ðŸ›  Setup instructions\n",
        "If required, install dependencies:**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GaojAcuYUdmw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy pandas matplotlib pillow torch torchvision eco2ai"
      ],
      "metadata": {
        "id": "ElMidmlalZ0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Suppress Future Warnings for Cleaner Output\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n"
      ],
      "metadata": {
        "id": "7iEK8-VtK6uy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import eco2ai\n",
        "from eco2ai import track"
      ],
      "metadata": {
        "id": "7TVD7pfJxuMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Core Libraries for Model Development and Utilities\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from PIL import Image\n",
        "import os"
      ],
      "metadata": {
        "id": "NakzrAyjyKyE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare and Load MNSIT Dataset\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
        "train_dataset"
      ],
      "metadata": {
        "id": "6NuudzQczUfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualise Sample Images\n",
        "fig, axs = plt.subplots(1, 10, figsize=(25, 3))\n",
        "for i in range(10):\n",
        "    label_indexes = [idx for idx, (_, label) in enumerate(train_dataset) if label == i]\n",
        "    index = random.choice(label_indexes)\n",
        "    img, _ = train_dataset[index]\n",
        "    axs[i].imshow(img.squeeze(), cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sicxju7LzvHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Data Loaders to Prepare Batches for Training and Testing\n",
        "batch_size = 256\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "xONnXox50hH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the CNN  Model Arhitecture\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.batch_norm = nn.BatchNorm2d(1)\n",
        "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(16, 16, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(16 * 14 * 14, 32)\n",
        "        self.fc2 = nn.Linear(32, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.batch_norm(x)\n",
        "        x = torch.relu(self.conv1(x))\n",
        "        x = torch.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.flatten(x)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "btJhzyhd2WVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Training and Evaluation Loop\n",
        "\n",
        "# Train the model and evaluate accuracy on the validation set\n",
        "def train(model, loader, criterion, optimizer, epochs=3):\n",
        "    history = {'train_acc': [], 'val_acc': []}\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train() # Set model to training mode\n",
        "        correct, total = 0, 0 # Track correct predictions and total samples\n",
        "\n",
        "        # Training Loop\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(device), y.to(device) # Move data to GPU or CPU\n",
        "            optimizer.zero_grad() # Clear previous gradients\n",
        "            outputs = model(x) # Forward pass: generate predictions\n",
        "            loss = criterion(outputs, y) # Compute loss against true labels\n",
        "            loss.backward() # Backpropagate gradients\n",
        "            optimizer.step() # Update weights\n",
        "\n",
        "\n",
        "            _, predicted = outputs.max(1) # Get class with highest score\n",
        "            total += y.size(0)\n",
        "            correct += (predicted == y).sum().item()\n",
        "\n",
        "        train_acc = correct / total  # Compute accuracy\n",
        "        history['train_acc'].append(train_acc)\n",
        "\n",
        "        # Validation Loop\n",
        "        model.eval() # Set model to evaluation mode\n",
        "        correct, total = 0, 0\n",
        "        with torch.no_grad(): # Disable gradient tracking during evaluation\n",
        "            for x, y in test_loader:\n",
        "                x, y = x.to(device), y.to(device)\n",
        "                outputs = model(x)\n",
        "                _, predicted = outputs.max(1)\n",
        "                total += y.size(0)\n",
        "                correct += (predicted == y).sum().item()\n",
        "\n",
        "        val_acc = correct / total # Compute validation accuracy\n",
        "        history['val_acc'].append(val_acc)\n",
        "\n",
        "        # Print summary after each epoch\n",
        "        print(f\"Epoch {epoch + 1}/{epochs}, Train Accuracy: {train_acc:.4f}, Val Accuracy: {val_acc:.4f}\")\n",
        "\n",
        "    return history # Return accuracy results for later use\n"
      ],
      "metadata": {
        "id": "YzJ0_8Cg8XAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Begin Emissions Tracking and Train Model\n",
        "\n",
        "# Emissions Tracking - Run 1 (3 Epochs, Batch Size = 256)\n",
        "tracker = eco2ai.Tracker(project_name=\"mnist_replication\", experiment_description=\"3 epochs, batch size 256\", file_name=\"emission.csv\")\n",
        "\n",
        "tracker.start() # Begin tracking energy usage and emissions\n",
        "\n",
        "# Define data loaders with a batch size of 256\n",
        "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)\n",
        "\n",
        "# Set up model, loss fucntion and optimiser\n",
        "model = SimpleCNN().to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the model for 3 epochs and collect accuracy stats\n",
        "history = train(model, train_loader, criterion, optimizer, epochs=3)\n",
        "\n",
        "tracker.stop() # End emissions tracking\n"
      ],
      "metadata": {
        "id": "BXv9z3YC8bTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Emissions Tracking â€“ Run 2 (2 Epochs, Batch Size = 128)\n",
        "\n",
        "# Trains the same CNN using a smaller batch size (128) and fewer epochs (2)\n",
        "# Useful for comparing how batch size and training time affect emissions and accuracy\n",
        "\n",
        "tracker = eco2ai.Tracker(project_name=\"mnist_replication\", experiment_description=\"2 epochs, batch size 128\", file_name=\"emission.csv\")\n",
        "tracker.start()\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
        "\n",
        "model = SimpleCNN().to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "history = train(model, train_loader, criterion, optimizer, epochs=2)\n",
        "\n",
        "tracker.stop()\n"
      ],
      "metadata": {
        "id": "luRTCyrq8g3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Emissions Tracking â€“ Run 3 (4 Epochs, Batch Size = 64)\n",
        "tracker = eco2ai.Tracker(project_name=\"mnist_replication\", experiment_description=\"4 epochs, batch size 64, SGD\", file_name=\"emission.csv\")\n",
        "tracker.start()\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "model = SimpleCNN().to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "history = train(model, train_loader, criterion, optimizer, epochs=4)\n",
        "\n",
        "tracker.stop()\n"
      ],
      "metadata": {
        "id": "frzSk2XO8kbX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the emissions CSV and display the last 3 tracked runs\n",
        "df = pd.read_csv(\"emission.csv\")\n",
        "display(df.tail(3))"
      ],
      "metadata": {
        "id": "jS0JjYUR8mgb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}